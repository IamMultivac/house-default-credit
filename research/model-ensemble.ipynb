{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f5bef6-4039-4a41-8a78-57a88fd6e5da",
   "metadata": {},
   "source": [
    "# Model ensemble\n",
    "\n",
    "## Rationale:\n",
    "\n",
    "Combining the predictions from different models has proved to be an excellent way to increase model performance in practice. So we are to aggregate the predicitons for our different models i.e. model that were found during feature selection process.\n",
    "\n",
    "## Methodology:\n",
    "\n",
    "We will ensemble the 5 different model predictions in 3 different ways:\n",
    "\n",
    "1. Using the average prediction for each model as the final prediction on the ```private dataset```\n",
    "2. We are to create a linear stacking model to combine the predictions for each model and then use this model for predicting the ```private dataset```. For doung so, first we need to generate the **Out of fold** predictions of every model and from this we are to train the staker model.\n",
    "3. We are to follow the same methodology as step 2 but using a non linear model, a **Multilayer perceptron** as stacker model.\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "**Conclusions from Model Performance Table:**\n",
    "\n",
    "1. **Prediction Averaging**: Models using prediction averaging techniques, such as 'prediction_average' and 'prediction_boruta,' consistently perform well with high ROC AUC scores in both out-of-fold and validation datasets.\n",
    "\n",
    "2. **Ensemble Models**: 'prediction_ensemble' and 'prediction_MrMr' exhibit competitive performance, indicating that ensemble techniques are effective for this task.\n",
    "\n",
    "3. **All Features Model**: The 'prediction_all_features' model, which includes all available features, performs respectably, demonstrating that feature selection methods might be further explored for optimization.\n",
    "\n",
    "4. **Optuna Optimization**: 'prediction_Optuna' shows slightly lower ROC AUC scores, suggesting that the specific optimization process may require further tuning or different hyperparameter settings.\n",
    "\n",
    "5. **Validation Dataset**: In general, the models perform slightly better on the validation dataset compared to the out-of-fold dataset, indicating that further validation and cross-validation might help in model selection.\n",
    "\n",
    "6. **Overall Strategy**: Depending on the specific goals and constraints of the project, different strategies (averaging, ensemble, feature selection) can be considered for achieving the desired performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| model                    | oof_roc_auc | validation_roc_auc |\n",
    "|--------------------------|------------|---------------------|\n",
    "| prediction_lr            | 0.795479   | 0.801554            |\n",
    "| prediction_average       | 0.795401   | 0.801386            |\n",
    "| prediction_boruta        | 0.795680   | 0.800874            |\n",
    "| prediction_ensemble      | 0.792880   | 0.799627            |\n",
    "| prediction_MrMr          | 0.792839   | 0.799425            |\n",
    "| prediction_all_features  | 0.791760   | 0.799144            |\n",
    "| prediction_Optuna        | 0.788259   | 0.795938            |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ece11e51-317a-4c77-a354-c65b68d3aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cloudpickle as cp\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# local imports\n",
    "from src.learner_params import target_column, space_column, boruta_learner_params, test_params\n",
    "from utils.functions__utils import find_constraint\n",
    "from utils.functions__utils import train_binary\n",
    "\n",
    "from utils.feature_selection_lists import fw_features, boruta_features, optuna_features, ensemble_features\n",
    "from utils.features_lists import all_features_list\n",
    "\n",
    "from src.learner_params import MODEL_PARAMS\n",
    "\n",
    "from utils.functions__training import model_pipeline\n",
    "\n",
    "from src.learner_params import params_all, params_ensemble, params_fw, params_optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceedd0b-0697-404b-a33e-b9b55e9132ec",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0918160-9518-46c4-84be-26aa03ffd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_pickle(\"../data/validation_df.pkl\")\n",
    "# load the datasets\n",
    "all_oof_df = pd.read_pickle(\"../data/all_oof_df.pkl\")\n",
    "boruta_oof_df = pd.read_pickle(\"../data/boruta_oof_df.pkl\")\n",
    "fw_oof_df = pd.read_pickle(\"../data/fw_oof_df.pkl\")\n",
    "optuna_oof_df = pd.read_pickle(\"../data/optuna_oof_df.pkl\")\n",
    "ensemble_oof_df = pd.read_pickle(\"../data/ensemble_oof_df.pkl\")\n",
    "# load the learners\n",
    "all_predict_fn = joblib.load(\"../model_files/all_learner.pkl\")\n",
    "boruta_predict_fn = joblib.load(\"../model_files/boruta_learner.pkl\")\n",
    "fw_predict_fn = joblib.load(\"../model_files/fw_learner.pkl\")\n",
    "optuna_predict_fn = joblib.load(\"../model_files/optuna_learner.pkl\")\n",
    "ensemble_predict_fn = joblib.load(\"../model_files/ensemble_learner.pkl\")\n",
    "\n",
    "ldf = [\n",
    "        all_oof_df,\n",
    "        boruta_oof_df,\n",
    "        fw_oof_df, \n",
    "        optuna_oof_df, \n",
    "        ensemble_oof_df\n",
    "]\n",
    "\n",
    "lpf = [all_predict_fn,\n",
    "       boruta_predict_fn,\n",
    "       fw_predict_fn,\n",
    "       optuna_predict_fn, \n",
    "       ensemble_predict_fn\n",
    "      ]\n",
    "\n",
    "names = [\"all_features\",\n",
    "        \"boruta\",\n",
    "        \"MrMr\",\n",
    "        \"Optuna\", \n",
    "        \"ensemble\"\n",
    "      ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b674b-7e41-490b-9fce-67f696eae6ce",
   "metadata": {},
   "source": [
    "### Join the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aef66fbd-47b0-4459-aa4a-1aa75c268f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, v = [], []\n",
    "\n",
    "for name, _df in zip(names, ldf):\n",
    "    aux = _df[[space_column, \"prediction\"]].rename(columns = {\"prediction\":f\"prediction_{name}\"})\n",
    "    l.append(aux)\n",
    "df_oof = reduce(lambda x,y:pd.merge(x,y, on = space_column), l)\n",
    "\n",
    "for name, predict_fn in zip(names, lpf):\n",
    "    aux = predict_fn[\"predict_fn\"](validation_df)[[space_column, \"prediction\"]].rename(columns = {\"prediction\":f\"prediction_{name}\"})\n",
    "    v.append(aux)\n",
    "df_validation = reduce(lambda x,y:pd.merge(x,y, on = space_column), v)\n",
    "\n",
    "columns = ['prediction_MrMr',\n",
    " 'prediction_Optuna',\n",
    " 'prediction_all_features',\n",
    " 'prediction_boruta',\n",
    " 'prediction_ensemble']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80910a86-6851-4d76-93f8-f55b5a5486aa",
   "metadata": {},
   "source": [
    "### Create the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8841a54e-dffa-4226-a765-fc7e1740b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof.loc[:,\"prediction_average\"] = df_oof.loc[:,columns].mean(axis = 1)\n",
    "df_validation.loc[:,\"prediction_average\"] = df_validation.loc[:,columns].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e72dfebf-d80e-48ba-8b04-fcee00504391",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(cv = 3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d68990f5-e7de-48c5-95ba-bc13841c9461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set for fold 1 is :0.798\n",
      "Score on test set for fold 2 is :0.795\n",
      "Score on test set for fold 3 is :0.794\n"
     ]
    }
   ],
   "source": [
    "aux = df_oof.merge(all_oof_df[[space_column, target_column]], on = space_column)\n",
    "result = train_binary(aux, columns, target_column, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d1aa0a4-b5d2-4564-9af5-f44b7258249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.loc[:,\"prediction_lr\"] = result[\"model\"].predict_proba(df_validation[columns])[:,1]\n",
    "df_oof = df_oof.merge(result[\"data\"][[space_column, \"prediction\"]], on = space_column)\n",
    "df_oof.rename(columns = {\"prediction\":\"prediction_lr\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "613ca10d-30c3-4c15-b529-568d3290d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = df_oof.merge(all_oof_df[[space_column, target_column]], on = space_column)\n",
    "df_validation = df_validation.merge(validation_df[[space_column, target_column]], on = space_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6e49b-c1a9-4ea2-bd7a-3dea770394e4",
   "metadata": {},
   "source": [
    "### Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3d5604c-543b-49a2-8d80-48f2ee10cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['prediction_MrMr',\n",
    " 'prediction_Optuna',\n",
    " 'prediction_all_features',\n",
    " 'prediction_boruta',\n",
    " 'prediction_ensemble',\n",
    " 'prediction_average', \n",
    " 'prediction_lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1ba244fb-4f22-4d4d-81f1-767e8d63acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = {}\n",
    "for col in columns:\n",
    "    ls[f\"{col}\"] = roc_auc_score(df_oof[target_column], df_oof[col])\n",
    "\n",
    "lv = {}\n",
    "for col in columns:\n",
    "    lv[f\"{col}\"] = roc_auc_score(df_validation[target_column], df_validation[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c121695-7d55-41f5-abfa-73425c3d3c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oof_roc_auc</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction_lr</th>\n",
       "      <td>0.795479</td>\n",
       "      <td>0.801554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_average</th>\n",
       "      <td>0.795401</td>\n",
       "      <td>0.801386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_boruta</th>\n",
       "      <td>0.795680</td>\n",
       "      <td>0.800874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_ensemble</th>\n",
       "      <td>0.792880</td>\n",
       "      <td>0.799627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_MrMr</th>\n",
       "      <td>0.792839</td>\n",
       "      <td>0.799425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_all_features</th>\n",
       "      <td>0.791760</td>\n",
       "      <td>0.799144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_Optuna</th>\n",
       "      <td>0.788259</td>\n",
       "      <td>0.795938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         oof_roc_auc  validation_roc_auc\n",
       "model                                                   \n",
       "prediction_lr               0.795479            0.801554\n",
       "prediction_average          0.795401            0.801386\n",
       "prediction_boruta           0.795680            0.800874\n",
       "prediction_ensemble         0.792880            0.799627\n",
       "prediction_MrMr             0.792839            0.799425\n",
       "prediction_all_features     0.791760            0.799144\n",
       "prediction_Optuna           0.788259            0.795938"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(pd.DataFrame(ls.items(), columns = [\"model\", \"oof_roc_auc\"]), \n",
    "         pd.DataFrame(lv.items(), columns = [\"model\", \"validation_roc_auc\"]),\n",
    "         on = \"model\").sort_values(by = \"validation_roc_auc\", ascending = False).set_index(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35d9c-9c0f-4e18-9404-e26e6703c275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
